{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "pd.options.mode.chained_assignment = None\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.reset_option(\"display.max_rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for patients who have records of verbal, motor, and eye opening scores at the same charttime, but don't have \n",
    "# GCS Total record for that charttime, add GCS Total record as the sum of the other 3 scores.\n",
    "\n",
    "def compute_gcs_total(table):\n",
    "    print(\"started processing - calculating total GCS\")\n",
    "    idents = sorted(table.identifier.unique())\n",
    "    new_rows = pd.DataFrame(columns=table.columns)\n",
    "    cnt = 0 #for prints\n",
    "    sum = 0\n",
    "    for iden in idents:\n",
    "        table_relevant_rows = table.loc[table['identifier'] == iden] # the rows of the specific identifier in table\n",
    "        charttimes = sorted(table_relevant_rows.charttime.unique()) # all charttimes of iden, sorted\n",
    "        for ctime in charttimes:\n",
    "            checkup_df = table_relevant_rows.loc[table_relevant_rows['charttime'] == ctime].reset_index(drop=True) #all checks conducted at the same time\n",
    "            if len(checkup_df) == 3: # all 3 checks were conducted, create a row of total score\n",
    "                row_to_add = checkup_df.loc[0]\n",
    "                gcs_total = checkup_df['score'].sum()\n",
    "                row_to_add['score'] = gcs_total\n",
    "                row_to_add['description'] = gcs_total\n",
    "                row_to_add['label'] = 'GCS Total'\n",
    "                new_rows = new_rows.append(row_to_add)\n",
    "        cnt += 1\n",
    "        if cnt == 200:\n",
    "            sum += cnt\n",
    "            cnt = 0\n",
    "            print(\"processing gcs - done {} patients.\".format(sum))\n",
    "    \n",
    "    new_table = pd.concat([table, new_rows])\n",
    "    print(\"rows to add: \", len(new_rows))\n",
    "    print('original len: ', len(table), \"new len: \", len(new_table))\n",
    "    #display(new_table)\n",
    "    new_table = new_table.sort_values(by=['identifier', 'charttime', 'label'])\n",
    "    \n",
    "    print(\"done processing.\")\n",
    "    return new_table\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculating only one feature that was selected for training the model (without calculating GCS Total)\n",
    "\n",
    "def create_gcs_features_limited(cohort, table, output_file_name, table_name):\n",
    "    print(\"started creating features from \",table_name)\n",
    "    table = table.dropna(subset = ['score']) #remove rows where score is null\n",
    "    # in the input patients who have GCS Total have only it, and those who don't have GCS Total have the other labels\n",
    "    # (1-3 of them). we want to remove those who have less then 3, because we can't calculate GCS Total for them.\n",
    "    total = table[table.label == 'GCS Total'] #save for later\n",
    "    table = table[table.label != 'GCS Total']\n",
    "    \n",
    "    grouped = table.groupby(['identifier','charttime'])\n",
    "    len_df = grouped.agg({'score': [len]}) # how many labels at each charttime every patient has\n",
    "    len_df.columns = len_df.columns.droplevel(0)\n",
    "    # remove those records that have less then 3 scores at one charttime:\n",
    "    to_remove = len_df.loc[(len_df['len'] == 1) | (len_df['len'] == 2)]\n",
    "    for index, row in to_remove.iterrows():\n",
    "        table = table.drop(table[(table.identifier == index[0]) & (table.charttime == index[1])].index)\n",
    "    # combine the remaining rows with the rows of GCS Total that we saved earlier:\n",
    "    table = pd.concat([table, total])\n",
    "    # Create the empty dataframe with all the identifiers:\n",
    "    cohort = cohort.sort_values(by=['identifier'])\n",
    "    idents = cohort['identifier']\n",
    "    feature = 'GCS Total, hours to target from first'\n",
    "    df = pd.DataFrame()\n",
    "    df['identifier'] = idents\n",
    "    df[feature] = np.nan\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    table = table.sort_values(by=['identifier', 'charttime'])\n",
    "\n",
    "    grouped = table.groupby('identifier')\n",
    "    first_df = grouped.first() # get the first record of every patient\n",
    "\n",
    "    # add the first measurement of each label to df_relevant_row:\n",
    "    for index, row in first_df.iterrows(): #index is the identifier\n",
    "        df.loc[df['identifier'] == index, [feature]] = row['hours_from_charttime_to_targettime']\n",
    "            \n",
    "    print(\"done creating features from \",table_name) \n",
    "    print(\"shape: \",df.shape)\n",
    "    \n",
    "    #display(df)\n",
    "    df.to_csv(output_file_name, encoding='utf-8', index=False)\n",
    "    \n",
    "    print(\"done creating {}_for_modeling.csv\\n\".format(table_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gcs_features_full(cohort, table, output_file_name, table_name):\n",
    "    print(\"started creating features from \",table_name)\n",
    "    table = compute_gcs_total(table)\n",
    "    table = table.dropna(subset = ['score']) #remove rows where score is null\n",
    "\n",
    "    # Create the empty dataframe with all the identifiers:\n",
    "    cohort = cohort.sort_values(by=['identifier'])\n",
    "    idents = cohort['identifier']\n",
    "    df = pd.DataFrame(idents, columns=['identifier'])\n",
    "\n",
    "    # for calculating stats for each label:\n",
    "    features = [' max', ' min', ' average', ' amount', ' first', ' last'] \n",
    "    # for calculating delta between the value of last measurement of the label and each stat:\n",
    "    stats = [' max', ' min', ' average', ' first']\n",
    "    delta_str = ', delta bw last,'\n",
    "    # for calculating the time from the min/max.. measurement for each label to target time (in hours):\n",
    "    time = [' max', ' min', ' last', ' first']\n",
    "    time_str = ', hours to target from' \n",
    "    \n",
    "    #create the columns with nan values:\n",
    "    labels = sorted(table.label.unique()) # all labels in table, sorted\n",
    "    for label in labels:\n",
    "        for feat in features:\n",
    "            df[label + feat] = np.nan\n",
    "    for label in labels:    \n",
    "        for stat in stats:\n",
    "            df[label + delta_str + stat] = np.nan\n",
    "    for label in labels:\n",
    "        for feat in time:\n",
    "            df[label + time_str + feat] = np.nan   \n",
    "    \n",
    "    # create the final df with all the statistics for all identifiers:\n",
    "    df_final = pd.DataFrame()\n",
    "    cnt = 0 #for prints\n",
    "    sum = 0\n",
    "    for iden in df['identifier']: \n",
    "    #iden = '10774-173586' for debug\n",
    "        df_relevant_row = df.loc[df['identifier'] == iden] # the row of the specific identifier in df\n",
    "        table_relevant_rows = table.loc[table['identifier'] == iden] # the rows of the specific identifier in table\n",
    "        grouped = table_relevant_rows.groupby('label')\n",
    "        stats_df = grouped.agg({'score': [np.max, np.min, np.average, len]})\n",
    "        stats_df.columns = stats_df.columns.droplevel(0)\n",
    "        stats_df.reset_index()\n",
    "\n",
    "        # add the calculated statistics from stat_df to the right cell in df_relevant_row\n",
    "        for label, row in stats_df.iterrows():\n",
    "            for feat in features[:-2]:\n",
    "                value = row[features.index(feat)]\n",
    "                df_relevant_row[label + feat] = value\n",
    "\n",
    "        # sort by charttime for extracting times and last value\n",
    "        table_relevant_rows = table_relevant_rows.sort_values(by=['label', 'charttime'])\n",
    "\n",
    "        grouped = table_relevant_rows.groupby('label')\n",
    "        last_df = grouped.last() # last measurement of each label\n",
    "        first_df = grouped.first() # firsr measurement of each label\n",
    "\n",
    "        # add the first measurement of each label to df_relevant_row:\n",
    "        for label, row in first_df.iterrows():\n",
    "            first_val = row['score']\n",
    "            df_relevant_row[label + ' first'] = first_val\n",
    "            #time from first measurement to target:\n",
    "            df_relevant_row[label + time_str + ' first'] = row['hours_from_charttime_to_targettime'] \n",
    "\n",
    "        # add delta between the last measurement and the different stats:\n",
    "        for label, row in last_df.iterrows():\n",
    "            last_val = row['score']\n",
    "            df_relevant_row[label + ' last'] = last_val #add the last measurement of the label to df_relevant_row\n",
    "            for stat in stats:\n",
    "                delta = last_val - df_relevant_row[label + stat]\n",
    "                df_relevant_row[label + delta_str + stat] = delta\n",
    "            #time from last measurement to target\n",
    "            df_relevant_row[label + time_str + ' last'] = row['hours_from_charttime_to_targettime'] \n",
    "\n",
    "            # add time from the min and max measurements to target time (in hours):\n",
    "            label_rows = table_relevant_rows.loc[table_relevant_rows['label'] == label]\n",
    "            for t_feat in time[:2]:\n",
    "                sc = df_relevant_row[label + t_feat].values[0]\n",
    "                sc_charttime = label_rows[label_rows['score'] == sc]['hours_from_charttime_to_targettime'].values[-1]\n",
    "                df_relevant_row[label + time_str + t_feat] = sc_charttime\n",
    "\n",
    "        #add the relevant row to final df:\n",
    "        df_final = pd.concat([df_final, df_relevant_row])\n",
    "\n",
    "        cnt += 1\n",
    "        if cnt == 200:\n",
    "            sum += cnt\n",
    "            cnt = 0\n",
    "            print(\"done {} patients.\".format(sum))\n",
    "    \n",
    "    print(\"done creating features from \",table_name) \n",
    "    print(\"shape: \",df_final.shape)\n",
    "\n",
    "    #display(df_final)\n",
    "    df_final.to_csv(output_file_name, encoding='utf-8', index=False)\n",
    "    \n",
    "    print(\"done creating {}_for_modeling.csv\\n\".format(table_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
